 \begin{table*}[!t]
    \centering
    \caption{\textbf{Comparison of image editing capabilities.} We evaluate on ImgEdit-Bench, GEdit-Bench, KRIS-Bench and WorldEdit. For ImgEdit-Bench, performance is evaluated across nine distinct operation categories (e.g., `Add', `Adjust', `Extract', `Replace', `Remove', `Background', `Style', `Hybrid', and `Action'. ). For GEdit-Bench, metrics include `G-Semantic Consistency' (G-SC) and `G-Perceptual Quality' (G-PQ). For KRIS-Bench, we report Factual (Fact.), Conceptual (Conc.), and Procedural (Proc.) knowledge scores. \textbf{Bold}: best results. \underline{Underline}: second-best.}
    \label{tab:img_edit}
    \scriptsize
    \setlength\tabcolsep{3 pt}
    \resizebox{\linewidth}{!}{ 
    \begin{tabular}{@{}lccccccccccccc|ccc|c|c@{}}
    \toprule
    \multicolumn{1}{l|}{} & \multicolumn{10}{c|}{\textbf{ImgEdit-Bench}} & \multicolumn{3}{c|}{\textbf{GEdit-Bench}} & \multicolumn{4}{c|}{\textbf{KRIS-Bench}} & \multicolumn{1}{c}{\textbf{WorldEdit}} \\ 
    \cmidrule(l){2-19}
    \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{Models}}} & \textbf{Add} & \textbf{Adj.} & \textbf{Ext.} & \textbf{Rep.} & \textbf{Rm.} & \textbf{Bg.} & \textbf{Sty.} & \textbf{Hyb.} & \multicolumn{1}{c|}{\textbf{Act.}} & \multicolumn{1}{c|}{\textbf{Overall}} & \textbf{G-SC} & \multicolumn{1}{c|}{\textbf{G-PQ}} & \textbf{G-Overall} & \textbf{Fact.} & \textbf{Conc.} & \multicolumn{1}{c|}{\textbf{Proc.}} & \textbf{Overall} & \textbf{Overall} \\ \midrule
    
    
    % --- Generation-only Models ---
    \rowcolor{highlightgray} 
    \multicolumn{19}{c}{\textit{Generation-only Models}} \\
    \multicolumn{1}{l|}{FLUX.1 Kontext {[}Pro{]} \citep{batifol2025flux}} & 4.25 & 4.15 & 2.35 & 4.56 & 3.57 & 4.26 & 4.57 & 3.68 & \multicolumn{1}{c|}{4.63} & \multicolumn{1}{c|}{4.00} & 7.02 & \multicolumn{1}{c|}{\underline{7.60}} & 6.56 & 57.22 & 55.06 & \multicolumn{1}{c|}{46.69} & 54.17 & \underline{3.21} \\
    \multicolumn{1}{l|}{Qwen-Image \citep{wu2025qwen}} & \underline{4.38} & \underline{4.16} & \textbf{3.43} & \underline{4.66} & 4.14 & \underline{4.38} & \textbf{4.81} & \underline{3.82} & \multicolumn{1}{c|}{\textbf{4.69}} & \multicolumn{1}{c|}{\underline{4.27}} & \underline{8.00} & \multicolumn{1}{c|}{\textbf{7.86}} & \textbf{7.56} & - & - & \multicolumn{1}{c|}{-} & - & - \\ \midrule
    
    % --- Specialized Editing Models ---
    \rowcolor{highlightgray} 
    \multicolumn{19}{c}{\textit{Specialized Editing Models}} \\
    \multicolumn{1}{l|}{Instruct-Pix2Pix \citep{brooks2023instructpix2pix}} & 2.45 & 1.83 & 1.44 & 2.01 & 1.50 & 1.44 & 3.55 & 1.20 & \multicolumn{1}{c|}{1.46} & \multicolumn{1}{c|}{1.88} & 3.58 & \multicolumn{1}{c|}{5.49} & 3.68 & 23.33 & 25.59 & \multicolumn{1}{c|}{17.28} & 22.82 & 2.44 \\
    \multicolumn{1}{l|}{MagicBrush \citep{zhang2023magicbrush}} & 2.84 & 1.58 & 1.51 & 1.97 & 1.58 & 1.75 & 2.38 & 1.62 & \multicolumn{1}{c|}{1.22} & \multicolumn{1}{c|}{1.83} & 4.68 & \multicolumn{1}{c|}{5.66} & 4.52 & 41.84 & 39.24 & \multicolumn{1}{c|}{26.54} & 37.15 & 2.14 \\
    \multicolumn{1}{l|}{AnyEdit \citep{yu2025anyedit}} & 3.18 & 2.95 & 1.88 & 2.47 & 2.23 & 2.24 & 2.85 & 1.56 & \multicolumn{1}{c|}{2.65} & \multicolumn{1}{c|}{2.45} & 3.18 & \multicolumn{1}{c|}{5.82} & 3.21 & 39.26 & 41.88 & \multicolumn{1}{c|}{31.74} & 38.55 & 2.09 \\
    \multicolumn{1}{l|}{Step1X-Edit \citep{liu2025step1x-edit}} & 3.88 & 3.14 & 1.76 & 3.40 & 2.41 & 3.16 & 4.63 & 2.64 & \multicolumn{1}{c|}{2.52} & \multicolumn{1}{c|}{3.06} & 7.09 & \multicolumn{1}{c|}{6.76} & 6.70 & 45.52 & 48.01 & \multicolumn{1}{c|}{31.82} & 43.29 & - \\ \midrule
    
    % --- Native or Composite UMMs ---
    \rowcolor{highlightgray} 
    \multicolumn{19}{c}{\textit{Unified Multimodal Models}} \\
    \multicolumn{1}{l|}{OmniGen \citep{xiao2025omnigen}} & 3.47 & 3.04 & 1.71 & 2.94 & 2.43 & 3.21 & 4.19 & 2.24 & \multicolumn{1}{c|}{3.38} & \multicolumn{1}{c|}{2.96} & 5.96 & \multicolumn{1}{c|}{5.89} & 5.06 & 33.11 & 28.02 & \multicolumn{1}{c|}{23.89} & 28.85 & 2.52 \\
    \multicolumn{1}{l|}{Ming-Univision \citep{huang2025ming}} & - & - & - &-  & - & - &-  & - & \multicolumn{1}{c|}{-} & \multicolumn{1}{c|}{-} & 6.04 & \multicolumn{1}{c|}{6.86} & 5.54 & - & - & \multicolumn{1}{c|}{-} & - & - \\
    \multicolumn{1}{l|}{BAGEL \citep{deng2025emerging}} & 3.56 & 3.31 & 1.70 & 3.30 & 2.62 & 3.24 & 4.49 & 2.38 & \multicolumn{1}{c|}{4.17} & \multicolumn{1}{c|}{3.20} & 7.36 & \multicolumn{1}{c|}{6.83} & 6.52 & \underline{60.26} & \underline{55.86} & \multicolumn{1}{c|}{\underline{51.69}} & \underline{56.21} & 2.76 \\
    \multicolumn{1}{l|}{UniWorld-V1 \citep{lin2025uniworld}} & 3.82 & 3.64 & 2.27 & 3.47 & 3.24 & 2.99 & 4.21 & 2.96 & \multicolumn{1}{c|}{2.74} & \multicolumn{1}{c|}{3.26} & 4.93 & \multicolumn{1}{c|}{7.43} & 4.85 & - & - & \multicolumn{1}{c|}{-} & - & - \\
    \multicolumn{1}{l|}{OmniGen2 \citep{wu2025omnigen2}} & 3.57 & 3.06 & 1.77 & 3.74 & 3.20 & 3.57 & \textbf{4.81} & 2.52 & \multicolumn{1}{c|}{\underline{4.68}} & \multicolumn{1}{c|}{3.44} & 7.16 & \multicolumn{1}{c|}{6.77} & 6.41 & 57.36 & 44.20 & \multicolumn{1}{c|}{47.79} & 49.71 & 2.51 \\ 
     \multicolumn{1}{l|}{TUNA~\citep{liu2025tuna}} & \textbf{4.46} & \textbf{4.52} & 2.47 & \textbf{4.68} & \textbf{4.58} & \textbf{4.56} & 4.73 & \textbf{4.07} & \multicolumn{1}{c|}{\textbf{4.69}} & \multicolumn{1}{c|}{\textbf{4.31}} & 7.79 & \multicolumn{1}{c|}{7.48} & 7.29 & - & - & - & - & - \\
    \rowcolor{mygreen}
    \multicolumn{1}{l|}{\textbf{UniCom (Ours)}} & 4.36  & 4.04 & \underline{3.30}  & 4.63 & \underline{4.40} & 4.24 & \underline{4.79} & 3.54 & \multicolumn{1}{c|}{\textbf{4.69}} & \multicolumn{1}{c|}{4.22} & \textbf{8.06} & \multicolumn{1}{c|}{7.33} & \underline{7.32} & \textbf{74.63} & \textbf{69.48} & \multicolumn{1}{c|}{\textbf{65.30}} & \textbf{70.11} & \textbf{4.35} \\
    \bottomrule
    \end{tabular}}
    \end{table*}